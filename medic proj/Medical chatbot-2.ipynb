{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIRTUAL MEDIC CHATBOT FOR DISEASE AND DRUG CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRESENTED BY:\n",
    "\n",
    "## Shyam R -19MIC0017\n",
    "## Niketha S-19MIC0035\n",
    "## Nivethitha S-19MIC0030\n",
    "## Ram Gnaneshwaran -19MIC0104\n",
    "## Nihaal Ahmed -19MIC0038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM:\n",
    "\n",
    "## In this project, we aim to build an end-to-end open source information retriveval medical chatbot\n",
    "## Our chatbot incorporates best practices in IR with a transformer-based reader to give answers quickly and efficiently from a huge corpus of medically related data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shyamr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/shyamr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import math\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from statistics import mean\n",
    "from nltk.corpus import wordnet \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import operator\n",
    "import warnings\n",
    "from Treatment import diseaseDetail\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\")\n",
    "documentname_list=list(df['label_dis'])\n",
    "df=df.iloc[:,1:]\n",
    "columns_name=list(df.columns)\n",
    "documentname_list=list(documentname_list)\n",
    "\n",
    "N=len(df)\n",
    "M=len(columns_name)\n",
    "idf={}\n",
    "for col in columns_name:\n",
    "  temp=np.count_nonzero(df[col])\n",
    "  idf[col]=np.log(N/temp)\n",
    "tf={}\n",
    "for i in range(N):\n",
    "  for col in columns_name:\n",
    "    key=(documentname_list[i],col)\n",
    "    tf[key]=df.loc[i,col]\n",
    "tf_idf={}\n",
    "for i in range(N):\n",
    "  for col in columns_name:\n",
    "    key=(documentname_list[i],col)\n",
    "    tf_idf[key]=float(idf[col])*float(tf[key])\n",
    "\n",
    "D = np.zeros((N, M),dtype='float32')\n",
    "for i in tf_idf:\n",
    "    sym = columns_name.index(i[1])\n",
    "    dis=documentname_list.index(i[0])\n",
    "    D[dis][sym] = tf_idf[i]\n",
    "\n",
    "def cosine_dot(a, b):\n",
    "    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        temp = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "        return temp\n",
    "\n",
    "\n",
    "def convert_tolowercase(data):\n",
    "    return data.lower()\n",
    "\n",
    "\n",
    "def regextokenizer_func(data):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data = tokenizer.tokenize(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_vector(tokens):\n",
    "    Q = np.zeros(M)\n",
    "    counter = Counter(tokens)\n",
    "    query_weights = {}\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]\n",
    "        try:\n",
    "          idf_temp=idf[token]\n",
    "        except:\n",
    "          pass\n",
    "        try:\n",
    "            ind = columns_name.index(token)\n",
    "            Q[ind] = tf*idf_temp\n",
    "        except:\n",
    "            pass\n",
    "    return Q\n",
    "\n",
    "\n",
    "def tf_idf_score(k, query):\n",
    "    query_weights = {}\n",
    "    for key in tf_idf:\n",
    "        if key[1] in query:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "  \n",
    "    l = []\n",
    "    for i in query_weights[:k]:\n",
    "        l.append(i)\n",
    "    return l\n",
    "\n",
    " \n",
    "def cosine_similarity(k, query):\n",
    "    d_cosines = []\n",
    "    query_vector = gen_vector(query)\n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_dot(query_vector, d))\n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "  \n",
    "    final_display_disease={}\n",
    "    for lt in set(out):\n",
    "      final_display_disease[lt] = float(d_cosines[lt])\n",
    "    return final_display_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synonyms(term):\n",
    "    synonyms = []\n",
    "    response = requests.get('https://www.thesaurus.com/browse/{}'.format(term))\n",
    "    soup = BeautifulSoup(response.content,  \"html.parser\")\n",
    "    try:\n",
    "        container=soup.find('section', {'class': 'MainContentContainer'}) \n",
    "        row=container.find('div',{'class':'css-191l5o0-ClassicContentCard'})\n",
    "        row = row.find_all('li')\n",
    "        for x in row:\n",
    "            synonyms.append(x.get_text())\n",
    "    except:\n",
    "        None\n",
    "    for syn in wordnet.synsets(term):\n",
    "        synonyms+=syn.lemma_names()\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\") # Disease combination\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\") # Individual Disease\n",
    "Y = df_norm.iloc[:, 0:1]\n",
    "X = df_norm.iloc[:, 1:]\n",
    "dataset_symptoms = list(X.columns)\n",
    "diseases = list(set(Y['label_dis']))\n",
    "diseases.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome to our Virtual-Chatbot\n",
      "\n",
      "Enter symptoms:\n",
      "headache,body pain,\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello! Welcome to our Virtual-Chatbot\")\n",
    "user_symptoms = str(input(\"\\nEnter symptoms:\\n\")).lower().split(',')\n",
    "processed_user_symptoms=[]\n",
    "for sym in user_symptoms:\n",
    "    sym=sym.strip()\n",
    "    sym=sym.replace('-',' ')\n",
    "    sym=sym.replace(\"'\",'')\n",
    "    sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "    processed_user_symptoms.append(sym)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing the Symptoms entered\n",
      "['concern cephalalgia headache vexation head ache worry', 'pain in the ass pain soundbox trunk personify body pain eubstance ail pain sensation painful sensation consistence torso annoyance consistency physical structure pain in the neck painfulness infliction body dead body hurting botheration anguish nuisance hurt organic structure trouble bother', '']\n"
     ]
    }
   ],
   "source": [
    "user_symptoms = []\n",
    "for user_sym in processed_user_symptoms:\n",
    "    user_sym = user_sym.split()\n",
    "    str_sym = set()\n",
    "    for comb in range(1, len(user_sym)+1):\n",
    "        for subset in combinations(user_sym, comb):\n",
    "            subset=' '.join(subset)\n",
    "            subset = synonyms(subset) \n",
    "            str_sym.update(subset)\n",
    "    str_sym.add(' '.join(user_sym))\n",
    "    user_symptoms.append(' '.join(str_sym).replace('_',' '))\n",
    "print(\"Analysing the Symptoms entered\")\n",
    "print(user_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_symptoms = set()\n",
    "for idx, data_sym in enumerate(dataset_symptoms):\n",
    "    data_sym_split=data_sym.split()\n",
    "    for user_sym in user_symptoms:\n",
    "        count=0\n",
    "        for symp in data_sym_split:\n",
    "            if symp in user_sym.split():\n",
    "                count+=1\n",
    "        if count/len(data_sym_split)>0.5:\n",
    "            found_symptoms.add(data_sym)\n",
    "found_symptoms = list(found_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching symptoms from the data entered\n",
      "0 : neck\n",
      "1 : painful\n",
      "2 : headache\n",
      "3 : trouble sensation\n",
      "\n",
      " Hello User! Select more relevant symptoms \n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Matching symptoms from the data entered\")\n",
    "for idx, symp in enumerate(found_symptoms):\n",
    "    print(idx,\":\",symp)\n",
    "\n",
    "select_list = input(\"\\n Hello User! Select more relevant symptoms \\n\").split()\n",
    "\n",
    "dis_list = set()\n",
    "final_symp = [] \n",
    "counter_list = []\n",
    "for idx in select_list:\n",
    "    symp=found_symptoms[int(idx)]\n",
    "    final_symp.append(symp)\n",
    "    dis_list.update(set(df_norm[df_norm[symp]==1]['label_dis']))\n",
    "   \n",
    "for dis in dis_list:\n",
    "    row = df_norm.loc[df_norm['label_dis'] == dis].values.tolist()\n",
    "    row[0].pop(0)\n",
    "    for idx,val in enumerate(row[0]):\n",
    "        if val!=0 and dataset_symptoms[idx] not in final_symp:\n",
    "            counter_list.append(dataset_symptoms[idx])\n",
    "             \n",
    "dict_symp = dict(Counter(counter_list))\n",
    "dict_symp_tup = sorted(dict_symp.items(), key=operator.itemgetter(1),reverse=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common symptoms:\n",
      "0 : fever\n",
      "1 : testicular pain\n",
      "2 : vomiting\n",
      "3 : confusion\n",
      "4 : maculopapular rash\n",
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      "0 2 \n",
      "\n",
      "Common symptoms:\n",
      "0 : dizziness\n",
      "1 : nausea\n",
      "2 : sore throat\n",
      "3 : muscle weakness\n",
      "4 : red\n",
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      "1 2\n",
      "\n",
      "Common symptoms:\n",
      "0 : problem vision\n",
      "1 : seizure\n",
      "2 : tiredness\n",
      "3 : barky cough\n",
      "4 : muscle joint pain\n",
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      "2 4\n",
      "\n",
      "Common symptoms:\n",
      "0 : eyestrain\n",
      "1 : red eye\n",
      "2 : swollen lymph node\n",
      "3 : chest pain\n",
      "4 : dry damp skin\n",
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      "-1\n",
      "\n",
      "Common symptoms:\n",
      "0 : high body temperature\n",
      "1 : chill\n",
      "2 : yellow skin\n",
      "3 : mental change\n",
      "4 : vary depending part brain involved\n",
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "found_symptoms=[]\n",
    "count=0\n",
    "for tup in dict_symp_tup:\n",
    "    count+=1\n",
    "    found_symptoms.append(tup[0])\n",
    "    if count%5==0 or count==len(dict_symp_tup):\n",
    "        print(\"\\nCommon symptoms:\")\n",
    "        for idx,ele in enumerate(found_symptoms):\n",
    "            print(idx,\":\",ele)\n",
    "        select_list = input(\"Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\\n\").lower().split();\n",
    "        if select_list[0]=='no':\n",
    "            break\n",
    "        if select_list[0]=='-1':\n",
    "            found_symptoms = [] \n",
    "            continue\n",
    "        for idx in select_list:\n",
    "            final_symp.append(found_symptoms[int(idx)])\n",
    "        found_symptoms = []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final list of Symptoms used for prediction are : \n",
      "painful\n",
      "headache\n",
      "fever\n",
      "vomiting\n",
      "nausea\n",
      "sore throat\n",
      "tiredness\n",
      "muscle joint pain\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "print(\"Final list of Symptoms used for prediction are : \")\n",
    "for val in final_symp:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 diseases predicted based on TF_IDF Matching :\n",
      "\n",
      "0. Disease : Influenza \t Score : 11.37\n",
      "1. Disease : Mononucleosis \t Score : 8.73\n",
      "2. Disease : Dengue \t Score : 8.11\n",
      "3. Disease : Chickenpox \t Score : 7.42\n",
      "4. Disease : Lyme disease \t Score : 7.42\n",
      "5. Disease : Anthrax \t Score : 7.13\n",
      "6. Disease : Hepatitis A \t Score : 7.13\n",
      "7. Disease : Ebola \t Score : 6.5\n",
      "8. Disease : Scarlet fever \t Score : 6.5\n",
      "9. Disease : Acute encephalitis syndrome \t Score : 5.92\n",
      "\n",
      "To enter more details about the disease? Enter index of disease or '-1' to discontinue:\n",
      "2\n",
      "\n",
      "Dengue\n",
      "Other names -  Dengue, breakbone fever   \n",
      "Pronunciation -       /  ˈ  d  ɛ  ŋ  ɡ  i  ,   -  ɡ  eɪ  /         \n",
      "Specialty -  Infectious disease \n",
      "Symptoms -  Fever, headache, muscle and joint pain, rash   \n",
      "Complications -  Bleeding, low levels of blood platelets, dangerously low blood pressure   \n",
      "Usual onset -  3–14 days after exposure   \n",
      "Duration -  2–7 days   \n",
      "Causes -  Dengue virus by  Aedes  mosquitos   \n",
      "Diagnostic method -  Detecting antibodies to the virus or its RNA   \n",
      "Differential diagnosis -  Malaria, yellow fever, viral hepatitis, leptospirosis   \n",
      "Prevention -  Dengue fever vaccine, decreasing mosquito exposure   \n",
      "Treatment -  Supportive care, intravenous fluids, blood transfusions   \n",
      "Frequency -  390 million per year   \n",
      "Deaths -  ~40,000 (2017)   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topk1=tf_idf_score(k,final_symp)\n",
    "topk2=cosine_similarity(k,final_symp)\n",
    "print(f\"\\nTop {k} diseases predicted based on TF_IDF Matching :\\n\")\n",
    "i = 0\n",
    "topk1_index_mapping = {}\n",
    "for key, score in topk1:\n",
    "  print(f\"{i}. Disease : {key} \\t Score : {round(score, 2)}\")\n",
    "  topk1_index_mapping[i] = key\n",
    "  i += 1\n",
    "\n",
    "select = input(\"\\nTo enter more details about the disease? Enter index of disease or '-1' to discontinue:\\n\")\n",
    "if select!='-1':\n",
    "    dis=topk1_index_mapping[int(select)]\n",
    "    print()\n",
    "    print(diseaseDetail(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 disease based on Cosine Similarity Matching :\n",
      " \n",
      "0. Disease : Dengue \t Score : 0.46\n",
      "1. Disease : Influenza \t Score : 0.44\n",
      "2. Disease : Mononucleosis \t Score : 0.41\n",
      "3. Disease : Malaria \t Score : 0.36\n",
      "4. Disease : Impetigo \t Score : 0.32\n",
      "5. Disease : Lyme disease \t Score : 0.32\n",
      "6. Disease : Campylobacter infection \t Score : 0.27\n",
      "7. Disease : Diphtheria \t Score : 0.26\n",
      "8. Disease : Bubonic plague \t Score : 0.24\n",
      "9. Disease : Rocky Mountain spotted fever \t Score : 0.24\n",
      "\n",
      "More details about the disease? Enter index of disease or '-1' to discontinue and close the system:\n",
      "1\n",
      "\n",
      "Influenza\n",
      "Other names -  Flu, the flu, Grippe \n",
      "Specialty -  Infectious disease \n",
      "Symptoms -  Fever, runny nose, sore throat, muscle pain, headache, coughing, fatigue \n",
      "Usual onset -  1–4 days after exposure \n",
      "Duration -  2–8 days \n",
      "Causes -  Influenza viruses \n",
      "Prevention -  Hand washing, flu vaccines \n",
      "Medication -  Antiviral drugs such as oseltamivir \n",
      "Frequency -  3–5 million severe cases per year   \n",
      "Deaths -  >,290,000–650,000 deaths per year   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top {k} disease based on Cosine Similarity Matching :\\n \")\n",
    "topk2_sorted = dict(sorted(topk2.items(), key=lambda kv: kv[1], reverse=True))\n",
    "j = 0\n",
    "topk2_index_mapping = {}\n",
    "for key in topk2_sorted:\n",
    "  print(f\"{j}. Disease : {diseases[key]} \\t Score : {round(topk2_sorted[key], 2)}\")\n",
    "  topk2_index_mapping[j] = diseases[key]\n",
    "  j += 1\n",
    "\n",
    "    \n",
    "select = input(\"\\nMore details about the disease? Enter index of disease or '-1' to discontinue and close the system:\\n\")\n",
    "if select!='-1':\n",
    "    dis=topk2_index_mapping[int(select)]\n",
    "    print()\n",
    "    print(diseaseDetail(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "edf86afe7404491c6b44fb838a3116e549001815debcdc4764703fba4fdabcec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
